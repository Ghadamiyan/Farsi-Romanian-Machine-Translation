{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e643149",
   "metadata": {},
   "source": [
    "# Creating a dataset based on a movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a662a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b21cf",
   "metadata": {},
   "source": [
    "The time stamp and sentences were extracted differently using regex. The two dataframes containing the time stamp and the lines were unified, thus converting the subtitles format to csv. This procedure was done for the subtitles in each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3338f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.DataFrame(columns=['time_stamp'])\n",
    "df_s = pd.DataFrame(columns=['sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661620c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"-----_fa.txt\", \"r\", encoding=\"utf8\")\n",
    "\n",
    "for line in f:\n",
    "    \n",
    "    integer = re.compile(\"^\\d+$\")    # the integers were ignored (line id) as it's not the same for each movie\n",
    "    if integer.match(line):\n",
    "        pass\n",
    "    \n",
    "    time = re.compile(\"^(\\d\\d):(\\d\\d):(\\d\\d),(\\d\\d\\d) --> (\\d\\d):(\\d\\d):(\\d\\d),(\\d\\d\\d)$\")   \n",
    "    if time.match(line):             # the time stamp is the feature that helps us match the lines\n",
    "        time_stamp = line[0:8]\n",
    "        df_t.loc[len(df_t.index)] = pd.Series({'time_stamp':time_stamp})\n",
    "        \n",
    "    empty = re.compile(\"^$\")         # empty lines were ignored\n",
    "    if empty.match(line):\n",
    "        pass\n",
    "               \n",
    "        \n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6570302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"-------_fa.txt\", \"r\", encoding=\"utf8\")\n",
    "\n",
    "b = False\n",
    "for line in f:\n",
    "    \n",
    "    integer = re.compile(\"^\\d+$\")               # the entries containing something other than sentences were ignored\n",
    "    if integer.match(line):\n",
    "        b = False\n",
    "    \n",
    "    time = re.compile(\"^(\\d\\d):(\\d\\d):(\\d\\d),(\\d\\d\\d) --> (\\d\\d):(\\d\\d):(\\d\\d),(\\d\\d\\d)$\")\n",
    "    if time.match(line):\n",
    "        b = False\n",
    "        \n",
    "    empty = re.compile(\"^$\")\n",
    "    if empty.match(line):\n",
    "        b = False\n",
    "                                           \n",
    "    time_ = re.compile(\"^(\\d\\d):(\\d\\d):(\\d\\d),(\\d\\d\\d) --> (\\d\\d):(\\d\\d):(\\d\\d),(\\d\\d\\d)$\")\n",
    "    integer_ = re.compile(\"^\\d+$\")\n",
    "    empty_ = re.compile(\"^$\")\n",
    "    if integer_.match(line) or time_.match(line) or empty_.match(line):\n",
    "        b = False\n",
    "    \n",
    "    else:\n",
    "                             # the sentences were extracted considering the fact that some of them are on more than one row\n",
    "        if b == True:\n",
    "            \n",
    "            #sent = str(df_s.loc[len(df_s.index)-1].values) + str(' ') + line\n",
    "            df_s.loc[len(df_s.index)-1] = df_s.loc[len(df_s.index)-1].astype('str') + pd.Series({'sent':line})\n",
    "              \n",
    "        if b == False:\n",
    "            sent = line\n",
    "            df_s.loc[len(df_s.index)] = pd.Series({'sent':sent})\n",
    "            b = True\n",
    "                \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f67298",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [df_t[\"time_stamp\"], df_s[\"sent\"]]     #created a data frame for romanian\n",
    "\n",
    "headers = [\"time_stamp\", \"sent\"]\n",
    "\n",
    "df_fa = pd.concat(data, axis=1, keys=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52103219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fa.to_csv('-------_fa.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adc63a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00:00:42', 'şi acum de ziua lui Columbus\\nnu mergem la şcoală.\\n',\n",
       "       'و بخاطر او ما روز كلمبوس را\\nدر تمامي مدارس تعطيل اعلام ميكنيم\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fa.loc[5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63b099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
