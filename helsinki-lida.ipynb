{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "062ecb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4681d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('movies_df.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3020888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.15, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b02004",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean = False\n",
    "Train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b931399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-mul-en\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-mul-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15deedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "537c3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train():\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    X = train['fa']\n",
    "    y = train['ro']\n",
    "    max_epochs = 2\n",
    "    n_batches = 3\n",
    "    for epoch in tqdm(range(max_epochs)):\n",
    "        for i in tqdm(range(125)):\n",
    "            # making batches \n",
    "            local_X, local_y = X[i*n_batches:(i+1)*n_batches,], y[i*n_batches:(i+1)*n_batches,]\n",
    "            # preparing the data according to the model input\n",
    "            batch = tokenizer.prepare_seq2seq_batch(list(local_X),list(local_y),return_tensors='pt')\n",
    "            output = model(**batch)\n",
    "            # loss can be taken directly from the model output\n",
    "            loss = output.loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses = losses+loss\n",
    "    average = losses/len(df)\n",
    "    print('Loss: ' + str(average) )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676acf8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f91ba282b5640f495f055ce1721ba02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b8ec84a4ad4fd0a6f228f383255540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3426: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aec4e7775cf4df498efebb074191ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.2648, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = model_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "277d5378",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 3\n",
    "torch.save(model.state_dict(), f'{epoch}.mt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb542e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(columns=['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d95acff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, _ in enumerate(test.iloc[:,0]):\n",
    "    a = model.generate(**tokenizer.prepare_seq2seq_batch(test.iloc[n,1],return_tensors='pt'))\n",
    "    text = tokenizer.batch_decode(a)\n",
    "    df_pred.loc[len(df_pred.index)] = pd.Series({'pred':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e453ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for element in df_pred.iloc[:,0]:\n",
    "    #pred.append(element[0])\n",
    "    pred.append(word_tokenize(str(element)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9c9d1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = []\n",
    "for element in test.iloc[:,0]:\n",
    "    #gt.append(element)\n",
    "    gt.append([word_tokenize(str(element))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "85f6082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[:,0].to_csv('pred_fm3e.csv', index=False)\n",
    "df_pred.iloc[:,0].to_csv('gt_fm3e.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1f522d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00786789320409298"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "bleu_score(pred, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82806c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
