{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sravan1320/NMT/blob/main/fine_tune_hugging_face_translation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cV-pf35571ap"
   },
   "source": [
    "### If you dont want to use Wandb, disable Wandb otherwise optional\n",
    "\n",
    "references for WANDB\n",
    "https://analyticsindiamag.com/hands-on-guide-to-weights-and-biases-wandb-with-python-implementation/\n",
    "\n",
    "https://docs.wandb.ai/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "tmYJBBbwyiX3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"WANDB_DISABLED\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1hOFHi-x5UZ"
   },
   "source": [
    "# Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "SqADZ2Sgx5Ua",
    "outputId": "16d10e79-af3f-4a82-d9e6-9843292775aa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\alienware\\miniconda3\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\alienware\\miniconda3\\lib\\site-packages (4.15.0)\n",
      "Requirement already satisfied: sacrebleu in c:\\users\\alienware\\miniconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: torch in c:\\users\\alienware\\miniconda3\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\alienware\\miniconda3\\lib\\site-packages (0.1.96)\n",
      "Requirement already satisfied: packaging in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: dill in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from datasets) (1.22.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from datasets) (2022.1.0)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from packaging->datasets) (3.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: portalocker in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from sacrebleu) (2.3.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from sacrebleu) (0.8.9)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from portalocker->sacrebleu) (228)\n",
      "Requirement already satisfied: click in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\alienware\\miniconda3\\lib\\site-packages (from transformers) (3.19.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets transformers sacrebleu torch sentencepiece transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qN5RtJdM8xi5"
   },
   "source": [
    "Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "5xKFwtNEx5Uc",
    "outputId": "4a9ced50-0274-4031-9978-b91bfbc7d0a0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.15.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKkJGYY19I11"
   },
   "source": [
    "# Fine-tuning a model on a translation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "MX7DsEmOx5Ud",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"Helsinki-NLP/opus-mt-mul-en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fu45aGHIAQqM"
   },
   "source": [
    "### Loading the dataset\n",
    "\n",
    "We will use the [datasets](https://github.com/huggingface/datasets/tree/master/datasets/wmt16) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions load_dataset and load_metric. We use the English/Romanian part of the WMT dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "biPo8vFTx5Ue",
    "outputId": "2b9ffb11-dca6-4dc7-ecf5-9d6856a9281b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LqXNw9_BFQe"
   },
   "source": [
    "The dataset object itself is [datasetdict](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6hsuFL1Bwa6"
   },
   "source": [
    "To get a sense of how the data looks like, the following function will show some examples picked randomly in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6OLK8GQB8lK"
   },
   "source": [
    "You can call its compute method with your predictions and labels, which need to be list of decoded strings (list of list for the labels):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6HmkA7uCWRa"
   },
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "Before we can feed those texts to our model, we need to preprocess them. This is done by a Transformers Tokenizer which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n",
    "\n",
    "To do all of this, we instantiate our tokenizer with the AutoTokenizer.from_pretrained method, which will ensure:\n",
    "\n",
    "we get a tokenizer that corresponds to the model architecture we want to use,\n",
    "we download the vocabulary used when pretraining this specific checkpoint.\n",
    "That vocabulary will be cached, so it's not downloaded again the next time we run the cell.\n",
    "\n",
    "If you downloaded the model manually, you can provide model present directory instead of model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "agDlgrOix5Uj",
    "outputId": "ff092d00-3d4d-4a6f-bca5-f33a49a64c7d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/config.json from cache at C:\\Users\\Alienware/.cache\\huggingface\\transformers\\07abbdf03be1b9f5bb00584b076297530595fae883f8715a86b8ee70ba288ad9.209344e751b882bdde512ed43f02eefed0bd84b70b20c62d12070906bfff04a3\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-mul-en\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      64171\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 64171,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 64172,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 6,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 64171,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64172\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/source.spm from cache at C:\\Users\\Alienware/.cache\\huggingface\\transformers\\5ec31591d9130cc9be0872e6b3dc0b276e514ab96e68404ac4a876ff03cb413b.dbd4bc2544d5c9f8f0d109844726c1600fa95cf0ba770b54c146f702be6e55dc\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/target.spm from cache at C:\\Users\\Alienware/.cache\\huggingface\\transformers\\04af8f7f08d4f9631a30ca0d03443987401d9695bf3ea3608d03e8fdc963ba4d.3d41c70e02886667ca1d52dfee5dcdcb2bdde04fa9a9d93d9a501aeaf0b01b43\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/vocab.json from cache at C:\\Users\\Alienware/.cache\\huggingface\\transformers\\2985bd4f6dfdfd15950f1871299943ae5bdbf18d8b45057656c40732e3a9c387.ad3a2dd7de31562e1ac257c5b5471ccbd9420632ec3e8a4206a5694a3822f250\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/tokenizer_config.json from cache at C:\\Users\\Alienware/.cache\\huggingface\\transformers\\fe769cb76941fc3e7ffb4097a8aeadf20ef19703f3ded81ab51d127026e3ffb7.aa8dd0bbd53bfbfac98cb6e6a6b9afe0a0d9bbda4c18ee867f75b6e654d1d4cc\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/tokenizer.json from cache at None\n",
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/config.json from cache at C:\\Users\\Alienware/.cache\\huggingface\\transformers\\07abbdf03be1b9f5bb00584b076297530595fae883f8715a86b8ee70ba288ad9.209344e751b882bdde512ed43f02eefed0bd84b70b20c62d12070906bfff04a3\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-mul-en\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      64171\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 64171,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 64172,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 6,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 64171,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64172\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbih6yhKG9JB"
   },
   "source": [
    "You can directly call this tokenizer on one sentence or a pair of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "qvYg6BXJx5Ul",
    "outputId": "20923805-e42b-4099-a2c8-d645393029d4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[12899, 3, 73, 151, 18617, 58, 0], [302, 17, 675, 18617, 2, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "with tokenizer.as_target_tokenizer():\n",
    "    print(tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 88EC-B3A6\n",
      "\n",
      " Directory of C:\\Users\\Alienware\\Desktop\n",
      "\n",
      "01/17/2022  07:22 PM    <DIR>          .\n",
      "01/17/2022  07:22 PM    <DIR>          ..\n",
      "01/17/2022  12:54 AM    <DIR>          .ipynb_checkpoints\n",
      "12/29/2021  05:58 PM             2,702 æTorrent.lnk\n",
      "12/11/2021  01:56 PM           105,288 16523926_980916128706235_1051899573_o.png\n",
      "12/16/2021  10:36 PM           141,442 64fa674b-d341-46ff-9a02-faba283bd961.pdf\n",
      "01/17/2022  01:02 AM    <DIR>          archive\n",
      "01/17/2022  01:02 AM        39,340,674 archive.zip\n",
      "12/13/2021  12:10 PM           982,120 ASEPTCONN-AG-sonea (1).pdf\n",
      "01/07/2022  09:48 AM           982,120 ASEPTCONN-AG-sonea (2).pdf\n",
      "01/11/2022  12:05 PM           982,120 ASEPTCONN-AG-sonea.pdf\n",
      "11/29/2021  11:47 AM       147,252,696 autocad_plant_3d_2022_sdk_english_win_64bit_dlm.sfx.exe\n",
      "01/13/2022  11:34 AM         1,123,667 bilet.pdf\n",
      "01/17/2022  10:41 AM       653,088,243 CCdf.csv\n",
      "01/17/2022  01:00 AM    <DIR>          CCMatrix\n",
      "01/11/2022  12:48 PM           964,368 customize_autocad_p_id_to_your_needsv2 (1).pdf\n",
      "01/14/2022  03:25 PM           964,368 customize_autocad_p_id_to_your_needsv2.pdf\n",
      "01/17/2022  03:35 PM    <DIR>          database.aseptsoft\n",
      "12/22/2021  01:48 AM       157,090,988 detect-targets-in-radar-signals.zip\n",
      "12/31/2021  12:14 PM       157,548,544 EpicInstaller-13.0.0.msi\n",
      "01/16/2022  10:38 PM            31,227 extract.ipynb\n",
      "01/09/2022  08:22 PM    <DIR>          fa_IR\n",
      "01/09/2022  08:21 PM            13,310 file (1).xml\n",
      "01/09/2022  08:11 PM            13,310 file.xml\n",
      "01/04/2022  09:02 AM        22,003,348 Jeffrey-E.-Young-Janet-S.-Klosko-Cum-sa?-t?i-reinventezi-viat?a.pdf\n",
      "01/06/2022  05:22 PM           136,873 Lecture_0_Transcript.pdf\n",
      "11/29/2021  12:27 PM         1,201,664 LiteDB.Studio.exe\n",
      "12/18/2021  01:55 PM            59,023 MegaBug.png\n",
      "12/14/2021  11:53 PM             2,380 Microsoft Teams.lnk\n",
      "11/26/2021  11:39 AM        60,924,672 Miniconda3-latest-Windows-x86_64.exe\n",
      "01/05/2022  02:48 PM            56,346 MT (1).pdf\n",
      "01/04/2022  12:15 PM            56,346 MT.pdf\n",
      "01/10/2022  07:33 AM             2,402 Oanea - Chrome.lnk\n",
      "11/29/2021  11:46 AM       120,237,280 objectarx_for_autocad_2022_win_64bit_dlm.sfx.exe\n",
      "12/25/2021  03:03 PM             1,454 Opera GX Browser.lnk\n",
      "01/17/2022  03:55 PM    <DIR>          opus-mt-mul-en-finetuned-fa-to-ro\n",
      "01/05/2022  12:19 PM           519,900 P2.pptx\n",
      "12/09/2021  09:18 AM    <DIR>          PentruPFA\n",
      "12/28/2021  12:47 PM         3,155,413 PXL_20211228_124115902.jpg\n",
      "01/17/2022  07:20 PM            64,092 Python_slow.png\n",
      "12/11/2021  11:02 AM            40,548 RO85BTRLRONCRT0413387101.pdf\n",
      "01/16/2022  07:08 PM            25,536 ro-fa-code-from-tds.ipynb\n",
      "01/17/2022  07:22 PM            66,811 ro-fa-code-from-tds-7930cc.ipynb\n",
      "11/21/2021  09:39 AM           236,509 sample_submission.csv\n",
      "01/07/2022  11:49 AM         2,418,095 Signed Software Developer Aagreement.pdf\n",
      "01/07/2022  10:10 AM           738,295 Software Development agreement Oanea Smit.pdf\n",
      "12/28/2021  10:39 PM               874 Start Tor Browser.lnk\n",
      "12/22/2021  03:25 AM    <DIR>          test\n",
      "11/21/2021  09:39 AM           225,503 test.csv\n",
      "12/25/2021  02:54 PM        21,938,152 TLauncher-2.831-Installer-0.8.8.exe\n",
      "12/28/2021  10:36 PM    <DIR>          Tor Browser\n",
      "12/28/2021  10:34 PM        77,167,024 torbrowser-install-win64-11.0.3_en-US.exe\n",
      "12/22/2021  03:25 AM    <DIR>          train\n",
      "12/23/2021  10:18 PM                 0 train (1).csv\n",
      "11/21/2021  09:39 AM           666,509 train.csv\n",
      "01/07/2022  10:10 PM             2,477 Unreal Engine.lnk\n",
      "12/23/2021  10:04 PM             1,153 Untitled.ipynb\n",
      "01/02/2022  10:37 PM         8,369,755 UserBenchMark.exe\n",
      "12/29/2021  05:57 PM         1,825,376 uTorrent.exe\n",
      "12/26/2021  05:31 PM       108,383,472 VirtualBox-6.1.30-148432-Win.exe\n",
      "01/11/2022  10:14 AM         3,472,184 winrar-x64-610b3.exe\n",
      "01/09/2022  07:51 PM         1,016,640 winzip26-lan.exe\n",
      "              50 File(s)  1,595,643,293 bytes\n",
      "              12 Dir(s)  270,022,971,392 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgjkiP5wHNc0"
   },
   "source": [
    "conda install -c anaconda scikit-learnWe can then write the function that will preprocess our samples. We just feed them to the tokenizer with the argument truncation=True. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Alienware\\miniconda3\\Scripts\\conda-script.py\", line 11, in <module>\n",
      "    from conda.cli import main\n",
      "ModuleNotFoundError: No module named 'conda'\n"
     ]
    }
   ],
   "source": [
    "conda install -c anaconda scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('archive/train_df.csv')\n",
    "test_df = pd.read_csv('archive/test_df.csv')\n",
    "train_df['ro'] = train_df.ro.astype(str).apply(lambda x: x.replace('</i>', ''))\n",
    "test_df['ro'] = test_df.ro.astype(str).apply(lambda x: x.replace('</i>', ''))\n",
    "train_df['fa'] = train_df.fa.astype(str).apply(lambda x: x.replace('</i>', ''))\n",
    "test_df['fa'] = test_df.fa.astype(str).apply(lambda x: x.replace('</i>', ''))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(train_df, shuffle=True, test_size=len(train_df)//100, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset, dataset_dict\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "raw_datasets = dataset_dict.DatasetDict({'train':train_dataset, 'validation':val_dataset, 'test':test_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ro</th>\n",
       "      <th>fa</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Aceasta este viata pe care o doresc! \", Atunci...</td>\n",
       "      <td>این زندگی است که من می خواهم! »سپس گام بعدی سا...</td>\n",
       "      <td>CCMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Irmosul: Pe Dumnezeu Cuvântul cel din Dumnezeu...</td>\n",
       "      <td>اصلاً ابلیس یک-موجود- مکّاری است؛ به خدا قسم!</td>\n",
       "      <td>CCMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Fresno Pacific University - este posibil să se...</td>\n",
       "      <td>Fresno Pacific University - ممکن است در اینجا ...</td>\n",
       "      <td>CCMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>De ce vă amestecaţi într-o plăcere care.</td>\n",
       "      <td>۱ ۱ Im(</td>\n",
       "      <td>CCMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>De ce vă amestecaţi într-o plăcere care.</td>\n",
       "      <td>شرح حکایت 1 (</td>\n",
       "      <td>CCMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694925</th>\n",
       "      <td>2694925</td>\n",
       "      <td>Însănătoșirea lumii</td>\n",
       "      <td>بهبود سلامت جهان</td>\n",
       "      <td>CCMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694926</th>\n",
       "      <td>2694926</td>\n",
       "      <td>Dacă luăm în considerare doar ulterior, Red Mc...</td>\n",
       "      <td>اما اگر ما تنها حیات وحش مککام در تگزاس را با ...</td>\n",
       "      <td>CCMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694927</th>\n",
       "      <td>2694927</td>\n",
       "      <td>În Italia sunt din belşug.</td>\n",
       "      <td>من از ایتالیا ناخشنودم.</td>\n",
       "      <td>CCMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694928</th>\n",
       "      <td>2694928</td>\n",
       "      <td>Parteneriatul public privat reprezintă o soluţie.</td>\n",
       "      <td>جنگ بشردوستانه راه حل است.</td>\n",
       "      <td>CCMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694929</th>\n",
       "      <td>2694929</td>\n",
       "      <td>“Cine cântă acolo?”</td>\n",
       "      <td>کیست آن جا پیانو می زند...</td>\n",
       "      <td>CCMatrix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2694930 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                                                 ro  \\\n",
       "0                 0  Aceasta este viata pe care o doresc! \", Atunci...   \n",
       "1                 1  Irmosul: Pe Dumnezeu Cuvântul cel din Dumnezeu...   \n",
       "2                 2  Fresno Pacific University - este posibil să se...   \n",
       "3                 3           De ce vă amestecaţi într-o plăcere care.   \n",
       "4                 4           De ce vă amestecaţi într-o plăcere care.   \n",
       "...             ...                                                ...   \n",
       "2694925     2694925                                Însănătoșirea lumii   \n",
       "2694926     2694926  Dacă luăm în considerare doar ulterior, Red Mc...   \n",
       "2694927     2694927                         În Italia sunt din belşug.   \n",
       "2694928     2694928  Parteneriatul public privat reprezintă o soluţie.   \n",
       "2694929     2694929                                “Cine cântă acolo?”   \n",
       "\n",
       "                                                        fa    source  \n",
       "0        این زندگی است که من می خواهم! »سپس گام بعدی سا...  CCMatrix  \n",
       "1            اصلاً ابلیس یک-موجود- مکّاری است؛ به خدا قسم!  CCMatrix  \n",
       "2        Fresno Pacific University - ممکن است در اینجا ...  CCMatrix  \n",
       "3                                                  ۱ ۱ Im(  CCMatrix  \n",
       "4                                            شرح حکایت 1 (  CCMatrix  \n",
       "...                                                    ...       ...  \n",
       "2694925                                   بهبود سلامت جهان  CCMatrix  \n",
       "2694926  اما اگر ما تنها حیات وحش مککام در تگزاس را با ...  CCMatrix  \n",
       "2694927                            من از ایتالیا ناخشنودم.  CCMatrix  \n",
       "2694928                         جنگ بشردوستانه راه حل است.  CCMatrix  \n",
       "2694929                         کیست آن جا پیانو می زند...  CCMatrix  \n",
       "\n",
       "[2694930 rows x 4 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ro</th>\n",
       "      <th>fa</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61903</td>\n",
       "      <td>Nu-mi place de loc neutralitatea în viaţă, în ...</td>\n",
       "      <td>من خنثی بودن را نه در زندگی و نه در هیچ چیز دی...</td>\n",
       "      <td>TED2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53955</td>\n",
       "      <td>Am fost ales să construiesc un pavilion din tu...</td>\n",
       "      <td>بنابراین از من خواسته شد که که غرفه‌ای از لوله...</td>\n",
       "      <td>TED2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290703</td>\n",
       "      <td>când ne socoteam deopotrivă cu Domnul lumilor!</td>\n",
       "      <td>چرا که شما را با پروردگار جهانیان برابر می‌شمر...</td>\n",
       "      <td>Tanzil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91500</td>\n",
       "      <td>De ce? Am scris o carte în care am încercat să...</td>\n",
       "      <td>چرا؟ من یک کتاب کامل نوشته‌ام تا این موضوع را ...</td>\n",
       "      <td>TED2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>266235</td>\n",
       "      <td>În ultimul deceniu, șapte milioane de străini ...</td>\n",
       "      <td>در طی دهه گذشته، هفت میلیون خارجی شهروندی آمری...</td>\n",
       "      <td>TED2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348879</th>\n",
       "      <td>119879</td>\n",
       "      <td>Femeile si copii, in special cei saraci, sunt ...</td>\n",
       "      <td>بچه ها و زنان، بخصوص فقرا، در قسمت پایین آن نر...</td>\n",
       "      <td>TED2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348880</th>\n",
       "      <td>259178</td>\n",
       "      <td>Dacă veţi număra binefacerile lui Dumnezeu, nu...</td>\n",
       "      <td>(خداوند جز اینها دارای نعمتهای فراوان دیگری اس...</td>\n",
       "      <td>Tanzil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348881</th>\n",
       "      <td>131932</td>\n",
       "      <td>În Ziua când pământul se va despica deasupra l...</td>\n",
       "      <td>روزى كه زمين به سرعت از [اجساد] آنان جدا و شكا...</td>\n",
       "      <td>Tanzil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348882</th>\n",
       "      <td>146867</td>\n",
       "      <td>Și adevărul este că nu înțeleg pe deplin tot c...</td>\n",
       "      <td>و حقیقت اینست که من در واقع بسیاری از چیزهاییک...</td>\n",
       "      <td>TED2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348883</th>\n",
       "      <td>121958</td>\n",
       "      <td>Conectarea la serverul proxy a eșuat.</td>\n",
       "      <td>نمی‌توان به کارگزار پیشکار متصل شد.</td>\n",
       "      <td>GNOME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>348884 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                                 ro  \\\n",
       "0            61903  Nu-mi place de loc neutralitatea în viaţă, în ...   \n",
       "1            53955  Am fost ales să construiesc un pavilion din tu...   \n",
       "2           290703     când ne socoteam deopotrivă cu Domnul lumilor!   \n",
       "3            91500  De ce? Am scris o carte în care am încercat să...   \n",
       "4           266235  În ultimul deceniu, șapte milioane de străini ...   \n",
       "...            ...                                                ...   \n",
       "348879      119879  Femeile si copii, in special cei saraci, sunt ...   \n",
       "348880      259178  Dacă veţi număra binefacerile lui Dumnezeu, nu...   \n",
       "348881      131932  În Ziua când pământul se va despica deasupra l...   \n",
       "348882      146867  Și adevărul este că nu înțeleg pe deplin tot c...   \n",
       "348883      121958              Conectarea la serverul proxy a eșuat.   \n",
       "\n",
       "                                                       fa   source  \n",
       "0       من خنثی بودن را نه در زندگی و نه در هیچ چیز دی...  TED2020  \n",
       "1       بنابراین از من خواسته شد که که غرفه‌ای از لوله...  TED2020  \n",
       "2       چرا که شما را با پروردگار جهانیان برابر می‌شمر...   Tanzil  \n",
       "3       چرا؟ من یک کتاب کامل نوشته‌ام تا این موضوع را ...  TED2020  \n",
       "4       در طی دهه گذشته، هفت میلیون خارجی شهروندی آمری...  TED2020  \n",
       "...                                                   ...      ...  \n",
       "348879  بچه ها و زنان، بخصوص فقرا، در قسمت پایین آن نر...  TED2020  \n",
       "348880  (خداوند جز اینها دارای نعمتهای فراوان دیگری اس...   Tanzil  \n",
       "348881  روزى كه زمين به سرعت از [اجساد] آنان جدا و شكا...   Tanzil  \n",
       "348882  و حقیقت اینست که من در واقع بسیاری از چیزهاییک...  TED2020  \n",
       "348883                نمی‌توان به کارگزار پیشکار متصل شد.    GNOME  \n",
       "\n",
       "[348884 rows x 4 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = pd.concat(train_df, cc_matrix_df.iloc[:90000]).reset_index(drop=True))\n",
    "cc_matrix_df = pd.read_csv('CCdf.csv')\n",
    "train_df = pd.concat([train_df, cc_matrix_df.iloc[:99900]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "e1fnOpO6x5Um",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"fa\"\n",
    "target_lang = \"ro\"\n",
    "def preprocess_function(dataset):\n",
    "    inputs = dataset[source_lang]\n",
    "    targets = dataset[target_lang]\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[856, 2471, 176, 1860, 196, 6138, 176, 700, 910, 1164, 31228, 152, 910, 1164, 8595, 15634, 22522, 20870, 5520, 926, 259, 2, 0], [11976, 2958, 1613, 176, 1682, 856, 1635, 7255, 6836, 507, 507, 5280, 180, 17870, 26, 1613, 1682, 14321, 4184, 16823, 664, 723, 5174, 10297, 583, 19444, 259, 118, 2134, 1841, 3334, 7040, 21276, 2574, 5306, 11475, 2, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[1782, 20, 198, 731, 43, 300, 126, 22679, 721, 44754, 4, 1864, 71, 2199, 13642, 2671, 3, 4, 1864, 71, 97, 9026, 2, 0], [2694, 1016, 256, 9, 1884, 181, 2671, 484, 6, 9607, 8217, 126, 227, 47568, 224, 157, 37455, 2282, 43, 627, 1320, 94, 3409, 29864, 1429, 106, 31356, 2671, 2, 0]]}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(train_dataset[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8ZDByENHTtO"
   },
   "source": [
    "To apply this function on all the pairs of sentences in our dataset, we just use the map method of our dataset object we created earlier. This will apply the function on all the elements of all the splits in dataset, so our training, validation and testing data will be preprocessed in one single command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "uZlsJFZnx5Uo",
    "outputId": "ffb2f5f3-1127-4c74-8094-1605e531ead4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b48f6edf13f404f9bf1b1c6bba61f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/349 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6165ad4ea06f4e7fab0e44ae237ed5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82227e76e42c4df6b5e50b1bd2ebf0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'attention_mask', 'fa', 'input_ids', 'labels', 'ro', 'source'],\n",
       "        num_rows: 348884\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'attention_mask', 'fa', 'input_ids', 'labels', 'ro', 'source'],\n",
       "        num_rows: 3524\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'attention_mask', 'fa', 'input_ids', 'labels', 'ro', 'source'],\n",
       "        num_rows: 3300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4kA3jpsHcFE"
   },
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooZLnaC1HhBq"
   },
   "source": [
    "Now that our data is ready, we can download the pretrained model and fine-tune it. Since our task is of the sequence-to-sequence kind, we use the AutoModelForSeq2SeqLM class. Like with the tokenizer, the from_pretrained method will download and cache the model for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "IvrIjd-Lx5Uq",
    "outputId": "590f26cf-1df0-44d4-f5b2-106cad098bc4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/config.json from cache at C:\\Users\\Alienware/.cache\\huggingface\\transformers\\07abbdf03be1b9f5bb00584b076297530595fae883f8715a86b8ee70ba288ad9.209344e751b882bdde512ed43f02eefed0bd84b70b20c62d12070906bfff04a3\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-mul-en\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      64171\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 64171,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 64172,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 6,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 64171,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64172\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/pytorch_model.bin from cache at C:\\Users\\Alienware/.cache\\huggingface\\transformers\\e0ef6edd847faa26ca1da874ec3047f8ac37913f35dca2c4c53e09f2b2cfa815.75443f4852fd8fd6b54e698df144869ee7c051eccc3dc37543650340ff0cced0\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-mul-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPagNnmWHoQW"
   },
   "source": [
    "To instantiate a Seq2SeqTrainer, we will need to define three more things. The most important is the [Seq2SeqTrainingArguments](https://huggingface.co/transformers/main_classes/trainer.html#transformers.Seq2SeqTrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "qk2p1KEwx5Ur",
    "outputId": "29763c0e-e709-4219-f2c5-98c6dfd096b1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=6,\n",
    "    predict_with_generate=True,\n",
    "    gradient_accumulation_steps=5,\n",
    "#     fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9UUwvXCH8Op"
   },
   "source": [
    "Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the batch_size defined at the top of the cell and customize the weight decay. Since the Seq2SeqTrainer will save the model regularly and our dataset is quite large, we tell it to make three saves maximum. Lastly, we use the predict_with_generate option (to properly generate summaries) and activate mixed precision training (to go a bit faster).\n",
    "\n",
    "Model will save under **{model_name}-finetuned-{source_lang}-to-{target_lang}** directory\n",
    "\n",
    "Then, we need a special kind of data collator, which will not only pad the inputs to the maximum length in the batch, but also the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "qV9wfuvZx5Us",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jw7by60eH_p5"
   },
   "source": [
    "The last thing to define for our Seq2SeqTrainer is how to compute the metrics from the predictions. We need to define a function for this, which will just use the metric we loaded earlier, and we have to do a bit of pre-processing to decode the predictions into texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "mHqp_FFhx5Uu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_XK7px-IDkC"
   },
   "source": [
    "Then we just need to pass all of this along with our datasets to the Seq2SeqTrainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "c7zuF8rLx5Uy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1TskjmQIGKd"
   },
   "source": [
    "We can now finetune our model by just calling the train method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sonIRAfDx5Uz",
    "outputId": "b1e5fd5d-28c1-4c35-ccc2-da386f37ff47",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: Unnamed: 0, ro, source, fa.\n",
      "***** Running training *****\n",
      "  Num examples = 348884\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 40\n",
      "  Gradient Accumulation steps = 5\n",
      "  Total optimization steps = 52332\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1252' max='52332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1252/52332 5:17:01 < 215:54:39, 0.07 it/s, Epoch 0.14/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to opus-mt-mul-en-finetuned-fa-to-ro\\checkpoint-500\n",
      "Configuration saved in opus-mt-mul-en-finetuned-fa-to-ro\\checkpoint-500\\config.json\n",
      "Model weights saved in opus-mt-mul-en-finetuned-fa-to-ro\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-mul-en-finetuned-fa-to-ro\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-mul-en-finetuned-fa-to-ro\\checkpoint-500\\special_tokens_map.json\n",
      "Saving model checkpoint to opus-mt-mul-en-finetuned-fa-to-ro\\checkpoint-1000\n",
      "Configuration saved in opus-mt-mul-en-finetuned-fa-to-ro\\checkpoint-1000\\config.json\n",
      "Model weights saved in opus-mt-mul-en-finetuned-fa-to-ro\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-mul-en-finetuned-fa-to-ro\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-mul-en-finetuned-fa-to-ro\\checkpoint-1000\\special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-SSyPwox5U1",
    "outputId": "c06f1ef4-8a5e-49a7-ef48-3c4997d3623f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('opus-mt-mul-en-finetuned-fa-to-ro'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeLJF9PJINyR"
   },
   "source": [
    "Our fine tuned model already saved under *opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38000*\n",
    "\n",
    "Load the model and translate some text from english to romanian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kByQ_vxTx5U2",
    "outputId": "c2fef526-afee-4309-9bb5-aef945b31b56",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import MarianMTModel, MarianTokenizer\n",
    "# src_text = ['My name is Sarah and I live in London']\n",
    "\n",
    "# model_name = 'opus-mt-mul-en-finetuned-fa-to-ro/checkpoint-9000'\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# print(tokenizer.supported_language_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# src_text = raw_datasets['validation'][:5]['fa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4h_jIFZgx5U2",
    "outputId": "77d69535-6d1e-486b-df14-382718414698",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "# translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [tokenizer.decode(t, skip_special_tokens=True) for t in translated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raw_datasets['validation'][:5]['ro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
